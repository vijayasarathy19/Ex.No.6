Date:   20-11-25   Register No.:   212223080057 To design and implement a Python program that integrates multiple AI tools — OpenAI GPT, Google Gemini, and Hugging Face — for automating API interactions, comparing model outputs, and generating data-driven insights.  OpenAI GPT (gpt-3.5-turbo)   – Text generation and analytical reasoning  Google Gemini-Pro   – Contextual response generation  Hugging Face Transformers   – Local evaluation and sentiment judging This experiment demonstrates how to connect and operate   multiple AI models within a single Python workflow.  The program: 1.  Takes a   user query   related to any real-world topic (e.g., healthcare). 2.  Fetches   responses   from OpenAI GPT and Google Gemini. 3.  Performs   sentiment analysis   on both outputs using Hugging Face Transformers. 4.  Compares response latency, tone, and similarity. 5.  Automatically generates an   insight   highlighting agreements, divergences, or biases among the models. This represents a   multi-AI orchestration pattern   where each tool contributes unique analytical capabilities.  Ex. No.: 6 – Development of Python Code Compatible with Multiple AI Tools  Aim: AI Tools Used: Explanation: Python Code:  import   openai  from   transformers   import   pipeline  import   google . generativeai   as   genai  import   os ,  time ,  sys  # --- Configuration ---  try :      openai . api_key   =   os . environ . get ( "OPENAI_API_KEY" ,  "YOUR_OPENAI_API_KEY_PLACEHOLDER" )      gemini_api_key   =   os . environ . get ( "GEMINI_API_KEY" ,  "YOUR_GEMINI_API_KEY_PLACEHOLDER" )      genai . configure ( api_key = gemini_api_key )  except   Exception   as   e :      print ( f"Configuration Error:  { e } " )

     sys . exit ( 1 )  # --- Input Query ---  query   =   "Explain how AI can improve agricultural productivity and sustainability in developing co  # --- Model A: OpenAI GPT ---  def   openai_response ( prompt ):      try :          start   =   time . time ()          response   =   openai . ChatCompletion . create (              model = "gpt-3.5-turbo" ,              messages = [{ "role" :  "user" ,  "content" :  prompt }],              max_tokens = 150          )          latency   =   time . time ()  -   start          return   response . choices [ 0 ]. message . content . strip (),  latency      except   Exception   as   e :          return   f"OpenAI Error:  { e } " ,  0.0  # --- Model B: Google Gemini ---  def   gemini_response ( prompt ):      try :          start   =   time . time ()          model   =   genai . GenerativeModel ( "gemini-pro" )          response   =   model . generate_content ( prompt )          latency   =   time . time ()  -   start          return   response . text . strip (),  latency      except   Exception   as   e :          return   f"Gemini Error:  { e } " ,  0.0  # --- Model C: Hugging Face Sentiment Judge ---  def   sentiment_check ( text ):      analyzer   =   pipeline ( "sentiment-analysis" )      start   =   time . time ()      result   =   analyzer ( text )[ 0 ]      latency   =   time . time ()  -   start      return   result ,  latency  # --- Execution ---  print ( f"Running Multi-AI Evaluation for Query: \n ' { query } ' \n " )  # Get model responses  gpt_output ,  gpt_time   =   openai_response ( query ) gemini_output ,  gemini_time   =   gemini_response ( query )  # Display outputs  print ( "=== Model Outputs ===" )  print ( f" \n OpenAI GPT ( { gpt_time :.2f } s):  { gpt_output } " )  print ( f" \n Google Gemini ( { gemini_time :.2f } s):  { gemini_output } " )  # Analyze tone of each output  print ( " \n === Sentiment Analysis ===" ) gpt_sentiment ,  gpt_sent_time   =   sentiment_check ( gpt_output ) gemini_sentiment ,  gemini_sent_time   =   sentiment_check ( gemini_output )  print ( f"GPT Sentiment:  { gpt_sentiment }  (Time:  { gpt_sent_time :.2f } s)" )  print ( f"Gemini Sentiment:  { gemini_sentiment }  (Time:  { gemini_sent_time :.2f } s)" )  # --- Automated Insight Logic ---

The Python code successfully integrated   OpenAI GPT ,   Google Gemini , and   Hugging Face Transformers   to evaluate and compare AI-generated insights. The approach proved effective in combining multiple models for enhanced analysis, showing how multi-AI orchestration can improve automation, consistency, and bias detection in intelligent systems. The corresponding Python code executed successfully. Multi-model outputs were generated, compared, and analyzed automatically to produce actionable insights.  print ( " \n === Insight Generation ===" )  if   "data"   in   gpt_output . lower ()  and   "satellite"   in   gemini_output . lower ():      print ( "Insight: Both highlight data-driven and satellite-based solutions — strong convergence  elif   gpt_sentiment [ 'label' ]  !=   gemini_sentiment [ 'label' ]:      print ( f"Insight: Sentiment disagreement detected! GPT= { gpt_sentiment [ 'label' ] }  vs Gemini= { gem  else :      print ( "Insight: Models propose complementary strategies — combined output could yield an opti  Output (Sample):  Running Multi-AI Evaluation for Query: 'Explain how AI can improve agricultural productivity and sustainability in developing   countries.' === Model Outputs === OpenAI GPT (1.32s): AI can enhance agriculture through precision farming, crop monitoring, and   predictive analytics to reduce waste and cost. Google Gemini (2.15s): By integrating satellite data, AI-driven irrigation, and soil analysis,   rural farmers can make smarter, data-backed decisions. === Sentiment Analysis === GPT Sentiment: {'label': 'POSITIVE', 'score': 0.99} Gemini Sentiment: {'label': 'POSITIVE', 'score': 0.98} === Insight Generation === Insight: Both highlight data-driven and satellite-based solutions — strong convergence on   precision agriculture.  Conclusion: Result: